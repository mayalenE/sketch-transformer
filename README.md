#  Learning to generate human-like sketches with a (decoder-only) transformer network


<p align="center">
    <img src="sketching_cats.gif">
</p>

This repository is basically the combination of:
- **The Transformer model architecture** :rocket: and more specifically Andrej Karphathy's [nanoGPT architecture](https://www.youtube.com/watch?v=kCc8FmEb1nY) 
which happens to be the decoder-only version of the original Transformer model in ["Attention is all you Need"](https://arxiv.org/pdf/1706.03762.pdf) paper, 
and which also happens to the architecture of OpenAI's GPT-2 / GPT-3 models
- **A cool :smiley_cat:-drawing application** which I've dug up from old times (yes 2017 is old in the ML world)
from a very nice paper proposed by David Ha's and Douglas Eck's called [sketchRNN](https://arxiv.org/pdf/1704.03477.pdf), 
where they propose to train (recurrent) neural networks to learn to generate human-like doodles as a *sequence of strokes*, 
in a manner similar to how children learn to depict objects (and even abstract concepts) with only a few pen strokes


**Disclaimer:** This repository is just me finally playing with transformers around a fun project that I can combine with our CNC-drawing machine  :pencil2:
Nothing groundbreaking here and in fact I'm quite late to the party as a 2020 [SketchFormer](https://arxiv.org/pdf/2002.10381.pdf) paper by Ribeiro et al's already did something very similar, 
although with a slightly different architecture: I used a decoder-only architecture as well as a mixture density network (MDN) output layer whereas they used discretized or continuous but deterministic tokens. 
More below :point_down:

## How to run the code?

This repo contains a colab notebook `transformer_sketch_generation.ipynb`that you can download or run directly in your browser at: []()

When training the model with proposed hyperparameters on a V100 GPU, the code takes approximately 20 mins to run.
If you do not have a GPU I recommend playing with a smaller model by decreasing `embd` or `num_head`, and `n_layers`  for instance.


## What is going on?

### Model 

### Loss

### Dataset


### Training 

Below I show the training loss as well as samples generated by the model after every 1200 training step, where one training step here is one batch of 64 sketches.

We can see that before training (step 0), the sketches are very short because the pen action $p \in {0=draw,1=lift,2=end}$ is sampled randomly.

Shortly, the model learns to draw longer sequences with already curvy shapes reminiscent of face contours.
It then seems to learn semblance of eyes, ears, and weird moustaches (though not very coherent yet).  
![](training1.png)

After 6000 steps, it becomes more and more evident that the model has learned to capture the essential components of a cat sketch: 
a round face, two ears, two eyes, a nose and sometimes moustaches. Obviously the model is far from perfect and
there are still several failed scribbles and quite funny generalizations of cats (:smirk_cat:).

![](training2.png)

I've finally let the model train for a total of 24000 steps with the training/validation loss that kept going down (though the loss i'm plotting here is noisy as only estimated on 10 batches).

![](training3.png)

That's the kind of sketches we obtain at the end of training!
Despite all being quite silly to have such a big model (10M params, and yet so small wrt to GPT & cie) to
generate these cat doodles, I'm quite happy with the results and confident that more can be done to improve it even further. 

### Evaluation


## Playing with the  model
### Interacting with human sketches

### CNC-Drawing the results

## Next Steps

Things that I'd like to try next:
* Finetune model and hyper-parameters: learning rate decay, gradient clipping, etc
* Multi-class training on Quick Draw Dataset
* Multi-class training on [TU-Berlin Sketch Dataset](https://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/) where strokes are bezier curves represented by 6-tuples
* Class-conditioned Sketch Generation akin to [this paper](https://arxiv.org/pdf/2205.09391.pdf
* I'd looove to generate more artisty sketches in the style of these [one line art drawings](https://medium.com/@michellegemmeke/the-art-of-one-line-drawings-8cd8fd5a5af7), 
as I found them very poetic despite their minimalism (and could make great tattoo designs!) so if you know any open database of such drawings please let me know :pray: 

## License
This repository is licensed under the [MIT License](https://github.com/mayalenE/sketch-transformer/blob/main/LICENSE).
